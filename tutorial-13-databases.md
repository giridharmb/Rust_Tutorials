# Tutorial 13: Database Integration - PostgreSQL

## Setting Up PostgreSQL with Rust

This tutorial covers two popular PostgreSQL libraries: diesel (ORM) and sqlx (async SQL toolkit).

```toml
# Cargo.toml for diesel
[dependencies]
diesel = { version = "2.1", features = ["postgres", "r2d2", "chrono", "uuid"] }
dotenvy = "0.15"
serde = { version = "1.0", features = ["derive"] }
chrono = { version = "0.4", features = ["serde"] }
uuid = { version = "1.0", features = ["v4", "serde"] }
r2d2 = "0.8"

# Cargo.toml for sqlx
[dependencies]
sqlx = { version = "0.7", features = ["runtime-tokio-native-tls", "postgres", "uuid", "chrono", "migrate"] }
tokio = { version = "1", features = ["full"] }
dotenvy = "0.15"
serde = { version = "1.0", features = ["derive"] }
chrono = { version = "0.4", features = ["serde"] }
uuid = { version = "1.0", features = ["v4", "serde"] }
```

## Diesel: Schema-First ORM

```rust
// Setting up Diesel
// 1. Install diesel CLI: cargo install diesel_cli --no-default-features --features postgres
// 2. Create .env file: DATABASE_URL=postgres://user:password@localhost/mydb
// 3. Run: diesel setup
// 4. Create migration: diesel migration generate create_users

// migrations/xxxx_create_users/up.sql
/*
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    username VARCHAR(50) NOT NULL UNIQUE,
    email VARCHAR(100) NOT NULL UNIQUE,
    password_hash VARCHAR(255) NOT NULL,
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW()
);

CREATE TABLE posts (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    title VARCHAR(255) NOT NULL,
    content TEXT NOT NULL,
    published BOOLEAN NOT NULL DEFAULT FALSE,
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW()
);

CREATE INDEX idx_posts_user_id ON posts(user_id);
CREATE INDEX idx_posts_published ON posts(published);
*/

// src/schema.rs (generated by diesel)
diesel::table! {
    users (id) {
        id -> Uuid,
        username -> Varchar,
        email -> Varchar,
        password_hash -> Varchar,
        created_at -> Timestamp,
        updated_at -> Timestamp,
    }
}

diesel::table! {
    posts (id) {
        id -> Uuid,
        user_id -> Uuid,
        title -> Varchar,
        content -> Text,
        published -> Bool,
        created_at -> Timestamp,
        updated_at -> Timestamp,
    }
}

diesel::joinable!(posts -> users (user_id));
diesel::allow_tables_to_appear_in_same_query!(users, posts);

// src/models.rs
use diesel::prelude::*;
use chrono::NaiveDateTime;
use uuid::Uuid;
use serde::{Deserialize, Serialize};

#[derive(Queryable, Selectable, Identifiable, Debug, Serialize)]
#[diesel(table_name = crate::schema::users)]
pub struct User {
    pub id: Uuid,
    pub username: String,
    pub email: String,
    #[serde(skip_serializing)]
    pub password_hash: String,
    pub created_at: NaiveDateTime,
    pub updated_at: NaiveDateTime,
}

#[derive(Insertable, Deserialize)]
#[diesel(table_name = crate::schema::users)]
pub struct NewUser {
    pub username: String,
    pub email: String,
    pub password_hash: String,
}

#[derive(Queryable, Selectable, Identifiable, Associations, Debug, Serialize)]
#[diesel(belongs_to(User))]
#[diesel(table_name = crate::schema::posts)]
pub struct Post {
    pub id: Uuid,
    pub user_id: Uuid,
    pub title: String,
    pub content: String,
    pub published: bool,
    pub created_at: NaiveDateTime,
    pub updated_at: NaiveDateTime,
}

#[derive(Insertable, Deserialize)]
#[diesel(table_name = crate::schema::posts)]
pub struct NewPost {
    pub user_id: Uuid,
    pub title: String,
    pub content: String,
    pub published: Option<bool>,
}

// src/db.rs
use diesel::pg::PgConnection;
use diesel::r2d2::{self, ConnectionManager};
use dotenvy::dotenv;
use std::env;

pub type DbPool = r2d2::Pool<ConnectionManager<PgConnection>>;

pub fn establish_connection_pool() -> DbPool {
    dotenv().ok();
    let database_url = env::var("DATABASE_URL")
        .expect("DATABASE_URL must be set");
    
    let manager = ConnectionManager::<PgConnection>::new(database_url);
    r2d2::Pool::builder()
        .max_size(10)
        .build(manager)
        .expect("Failed to create pool")
}

// src/main.rs
use diesel::prelude::*;
use uuid::Uuid;

mod schema;
mod models;
mod db;

use models::{User, NewUser, Post, NewPost};

fn create_user(conn: &mut PgConnection, new_user: NewUser) -> QueryResult<User> {
    use crate::schema::users;
    
    diesel::insert_into(users::table)
        .values(&new_user)
        .get_result(conn)
}

fn find_user_by_email(conn: &mut PgConnection, user_email: &str) -> QueryResult<User> {
    use crate::schema::users::dsl::*;
    
    users
        .filter(email.eq(user_email))
        .first(conn)
}

fn update_user_username(
    conn: &mut PgConnection,
    user_id: Uuid,
    new_username: &str,
) -> QueryResult<User> {
    use crate::schema::users::dsl::*;
    
    diesel::update(users.find(user_id))
        .set(username.eq(new_username))
        .get_result(conn)
}

fn delete_user(conn: &mut PgConnection, user_id: Uuid) -> QueryResult<usize> {
    use crate::schema::users::dsl::*;
    
    diesel::delete(users.find(user_id))
        .execute(conn)
}

fn get_user_with_posts(conn: &mut PgConnection, user_id: Uuid) -> QueryResult<(User, Vec<Post>)> {
    use crate::schema::{users, posts};
    
    let user = users::table
        .find(user_id)
        .first::<User>(conn)?;
    
    let user_posts = Post::belonging_to(&user)
        .filter(posts::published.eq(true))
        .order(posts::created_at.desc())
        .load::<Post>(conn)?;
    
    Ok((user, user_posts))
}

fn search_posts(conn: &mut PgConnection, query: &str) -> QueryResult<Vec<(Post, User)>> {
    use crate::schema::{users, posts};
    
    posts::table
        .inner_join(users::table)
        .filter(posts::title.ilike(format!("%{}%", query))
            .or(posts::content.ilike(format!("%{}%", query))))
        .filter(posts::published.eq(true))
        .order(posts::created_at.desc())
        .limit(20)
        .select((Post::as_select(), User::as_select()))
        .load(conn)
}

fn main() {
    let pool = db::establish_connection_pool();
    let mut conn = pool.get().expect("Failed to get connection from pool");
    
    // Create a user
    let new_user = NewUser {
        username: "alice".to_string(),
        email: "alice@example.com".to_string(),
        password_hash: "hashed_password".to_string(),
    };
    
    match create_user(&mut conn, new_user) {
        Ok(user) => println!("Created user: {:?}", user),
        Err(e) => eprintln!("Error creating user: {}", e),
    }
    
    // Find user by email
    match find_user_by_email(&mut conn, "alice@example.com") {
        Ok(user) => {
            println!("Found user: {:?}", user);
            
            // Create a post for this user
            let new_post = NewPost {
                user_id: user.id,
                title: "My First Post".to_string(),
                content: "This is the content of my first post".to_string(),
                published: Some(true),
            };
            
            use crate::schema::posts;
            match diesel::insert_into(posts::table)
                .values(&new_post)
                .get_result::<Post>(&mut conn)
            {
                Ok(post) => println!("Created post: {:?}", post),
                Err(e) => eprintln!("Error creating post: {}", e),
            }
        }
        Err(e) => eprintln!("Error finding user: {}", e),
    }
    
    // Search posts
    match search_posts(&mut conn, "first") {
        Ok(results) => {
            for (post, user) in results {
                println!("Post '{}' by {}", post.title, user.username);
            }
        }
        Err(e) => eprintln!("Error searching posts: {}", e),
    }
}
```

## SQLx: Async SQL Toolkit

```rust
// src/main.rs for sqlx
use sqlx::postgres::{PgPool, PgPoolOptions};
use sqlx::{FromRow, Type};
use chrono::{DateTime, Utc};
use uuid::Uuid;
use serde::{Deserialize, Serialize};

#[derive(Debug, FromRow, Serialize)]
struct User {
    id: Uuid,
    username: String,
    email: String,
    #[serde(skip_serializing)]
    password_hash: String,
    created_at: DateTime<Utc>,
    updated_at: DateTime<Utc>,
}

#[derive(Debug, FromRow, Serialize)]
struct Post {
    id: Uuid,
    user_id: Uuid,
    title: String,
    content: String,
    published: bool,
    created_at: DateTime<Utc>,
    updated_at: DateTime<Utc>,
}

#[derive(Debug, Deserialize)]
struct CreateUserRequest {
    username: String,
    email: String,
    password: String,
}

#[derive(Debug, Deserialize)]
struct CreatePostRequest {
    title: String,
    content: String,
    published: Option<bool>,
}

// Database repository pattern
struct UserRepository {
    pool: PgPool,
}

impl UserRepository {
    fn new(pool: PgPool) -> Self {
        Self { pool }
    }
    
    async fn create(&self, req: CreateUserRequest) -> Result<User, sqlx::Error> {
        let user = sqlx::query_as!(
            User,
            r#"
            INSERT INTO users (username, email, password_hash)
            VALUES ($1, $2, $3)
            RETURNING id, username, email, password_hash, created_at, updated_at
            "#,
            req.username,
            req.email,
            hash_password(&req.password),
        )
        .fetch_one(&self.pool)
        .await?;
        
        Ok(user)
    }
    
    async fn find_by_id(&self, id: Uuid) -> Result<Option<User>, sqlx::Error> {
        let user = sqlx::query_as!(
            User,
            r#"
            SELECT id, username, email, password_hash, created_at, updated_at
            FROM users
            WHERE id = $1
            "#,
            id
        )
        .fetch_optional(&self.pool)
        .await?;
        
        Ok(user)
    }
    
    async fn find_by_email(&self, email: &str) -> Result<Option<User>, sqlx::Error> {
        let user = sqlx::query_as!(
            User,
            r#"
            SELECT id, username, email, password_hash, created_at, updated_at
            FROM users
            WHERE email = $1
            "#,
            email
        )
        .fetch_optional(&self.pool)
        .await?;
        
        Ok(user)
    }
    
    async fn update_username(&self, id: Uuid, username: &str) -> Result<User, sqlx::Error> {
        let user = sqlx::query_as!(
            User,
            r#"
            UPDATE users
            SET username = $1, updated_at = NOW()
            WHERE id = $2
            RETURNING id, username, email, password_hash, created_at, updated_at
            "#,
            username,
            id
        )
        .fetch_one(&self.pool)
        .await?;
        
        Ok(user)
    }
    
    async fn delete(&self, id: Uuid) -> Result<bool, sqlx::Error> {
        let result = sqlx::query!(
            r#"
            DELETE FROM users
            WHERE id = $1
            "#,
            id
        )
        .execute(&self.pool)
        .await?;
        
        Ok(result.rows_affected() > 0)
    }
}

struct PostRepository {
    pool: PgPool,
}

impl PostRepository {
    fn new(pool: PgPool) -> Self {
        Self { pool }
    }
    
    async fn create(&self, user_id: Uuid, req: CreatePostRequest) -> Result<Post, sqlx::Error> {
        let post = sqlx::query_as!(
            Post,
            r#"
            INSERT INTO posts (user_id, title, content, published)
            VALUES ($1, $2, $3, $4)
            RETURNING id, user_id, title, content, published, created_at, updated_at
            "#,
            user_id,
            req.title,
            req.content,
            req.published.unwrap_or(false)
        )
        .fetch_one(&self.pool)
        .await?;
        
        Ok(post)
    }
    
    async fn find_by_user(&self, user_id: Uuid) -> Result<Vec<Post>, sqlx::Error> {
        let posts = sqlx::query_as!(
            Post,
            r#"
            SELECT id, user_id, title, content, published, created_at, updated_at
            FROM posts
            WHERE user_id = $1
            ORDER BY created_at DESC
            "#,
            user_id
        )
        .fetch_all(&self.pool)
        .await?;
        
        Ok(posts)
    }
    
    async fn search(&self, query: &str) -> Result<Vec<(Post, User)>, sqlx::Error> {
        let results = sqlx::query!(
            r#"
            SELECT 
                p.id as post_id,
                p.user_id,
                p.title,
                p.content,
                p.published,
                p.created_at as post_created_at,
                p.updated_at as post_updated_at,
                u.id as user_id,
                u.username,
                u.email,
                u.password_hash,
                u.created_at as user_created_at,
                u.updated_at as user_updated_at
            FROM posts p
            INNER JOIN users u ON p.user_id = u.id
            WHERE p.published = true
                AND (p.title ILIKE $1 OR p.content ILIKE $1)
            ORDER BY p.created_at DESC
            LIMIT 20
            "#,
            format!("%{}%", query)
        )
        .fetch_all(&self.pool)
        .await?;
        
        let mut post_user_pairs = Vec::new();
        for row in results {
            let post = Post {
                id: row.post_id,
                user_id: row.user_id,
                title: row.title,
                content: row.content,
                published: row.published,
                created_at: row.post_created_at,
                updated_at: row.post_updated_at,
            };
            
            let user = User {
                id: row.user_id,
                username: row.username,
                email: row.email,
                password_hash: row.password_hash,
                created_at: row.user_created_at,
                updated_at: row.user_updated_at,
            };
            
            post_user_pairs.push((post, user));
        }
        
        Ok(post_user_pairs)
    }
}

// Transaction example
async fn create_user_with_initial_post(
    pool: &PgPool,
    user_req: CreateUserRequest,
    post_req: CreatePostRequest,
) -> Result<(User, Post), sqlx::Error> {
    let mut tx = pool.begin().await?;
    
    let user = sqlx::query_as!(
        User,
        r#"
        INSERT INTO users (username, email, password_hash)
        VALUES ($1, $2, $3)
        RETURNING id, username, email, password_hash, created_at, updated_at
        "#,
        user_req.username,
        user_req.email,
        hash_password(&user_req.password),
    )
    .fetch_one(&mut *tx)
    .await?;
    
    let post = sqlx::query_as!(
        Post,
        r#"
        INSERT INTO posts (user_id, title, content, published)
        VALUES ($1, $2, $3, $4)
        RETURNING id, user_id, title, content, published, created_at, updated_at
        "#,
        user.id,
        post_req.title,
        post_req.content,
        post_req.published.unwrap_or(false)
    )
    .fetch_one(&mut *tx)
    .await?;
    
    tx.commit().await?;
    
    Ok((user, post))
}

fn hash_password(password: &str) -> String {
    // In production, use a proper password hashing library like argon2
    format!("hashed_{}", password)
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    dotenvy::dotenv().ok();
    
    let database_url = std::env::var("DATABASE_URL")?;
    
    let pool = PgPoolOptions::new()
        .max_connections(10)
        .connect(&database_url)
        .await?;
    
    // Run migrations
    sqlx::migrate!("./migrations")
        .run(&pool)
        .await?;
    
    let user_repo = UserRepository::new(pool.clone());
    let post_repo = PostRepository::new(pool.clone());
    
    // Create a user
    let create_user_req = CreateUserRequest {
        username: "bob".to_string(),
        email: "bob@example.com".to_string(),
        password: "secure_password".to_string(),
    };
    
    match user_repo.create(create_user_req).await {
        Ok(user) => {
            println!("Created user: {:?}", user);
            
            // Create a post
            let create_post_req = CreatePostRequest {
                title: "Hello SQLx".to_string(),
                content: "SQLx is great for async database operations".to_string(),
                published: Some(true),
            };
            
            match post_repo.create(user.id, create_post_req).await {
                Ok(post) => println!("Created post: {:?}", post),
                Err(e) => eprintln!("Error creating post: {}", e),
            }
        }
        Err(e) => eprintln!("Error creating user: {}", e),
    }
    
    // Transaction example
    let user_req = CreateUserRequest {
        username: "charlie".to_string(),
        email: "charlie@example.com".to_string(),
        password: "password123".to_string(),
    };
    
    let post_req = CreatePostRequest {
        title: "My Introduction".to_string(),
        content: "Hello, I'm new here!".to_string(),
        published: Some(true),
    };
    
    match create_user_with_initial_post(&pool, user_req, post_req).await {
        Ok((user, post)) => {
            println!("Created user with post: {:?}, {:?}", user, post);
        }
        Err(e) => eprintln!("Transaction failed: {}", e),
    }
    
    Ok(())
}
```

## Advanced Database Patterns

```rust
// src/pagination.rs
use serde::{Deserialize, Serialize};
use sqlx::PgPool;
use uuid::Uuid;

#[derive(Debug, Deserialize)]
pub struct PaginationParams {
    pub page: Option<i64>,
    pub per_page: Option<i64>,
}

impl Default for PaginationParams {
    fn default() -> Self {
        Self {
            page: Some(1),
            per_page: Some(20),
        }
    }
}

#[derive(Debug, Serialize)]
pub struct PaginatedResponse<T> {
    pub data: Vec<T>,
    pub total: i64,
    pub page: i64,
    pub per_page: i64,
    pub total_pages: i64,
}

pub async fn paginate_posts(
    pool: &PgPool,
    params: PaginationParams,
) -> Result<PaginatedResponse<Post>, sqlx::Error> {
    let page = params.page.unwrap_or(1).max(1);
    let per_page = params.per_page.unwrap_or(20).min(100);
    let offset = (page - 1) * per_page;
    
    // Count total
    let total = sqlx::query_scalar!(
        r#"
        SELECT COUNT(*) as count
        FROM posts
        WHERE published = true
        "#
    )
    .fetch_one(pool)
    .await?
    .unwrap_or(0);
    
    // Fetch page
    let posts = sqlx::query_as!(
        Post,
        r#"
        SELECT id, user_id, title, content, published, created_at, updated_at
        FROM posts
        WHERE published = true
        ORDER BY created_at DESC
        LIMIT $1 OFFSET $2
        "#,
        per_page,
        offset
    )
    .fetch_all(pool)
    .await?;
    
    let total_pages = (total as f64 / per_page as f64).ceil() as i64;
    
    Ok(PaginatedResponse {
        data: posts,
        total,
        page,
        per_page,
        total_pages,
    })
}

// src/connection_pool.rs
use sqlx::postgres::{PgPool, PgPoolOptions};
use std::time::Duration;

pub struct DatabaseConfig {
    pub url: String,
    pub max_connections: u32,
    pub min_connections: u32,
    pub connect_timeout: Duration,
    pub idle_timeout: Duration,
    pub max_lifetime: Duration,
}

impl Default for DatabaseConfig {
    fn default() -> Self {
        Self {
            url: String::new(),
            max_connections: 10,
            min_connections: 2,
            connect_timeout: Duration::from_secs(30),
            idle_timeout: Duration::from_secs(600),
            max_lifetime: Duration::from_secs(1800),
        }
    }
}

pub async fn create_pool(config: DatabaseConfig) -> Result<PgPool, sqlx::Error> {
    PgPoolOptions::new()
        .max_connections(config.max_connections)
        .min_connections(config.min_connections)
        .connect_timeout(config.connect_timeout)
        .idle_timeout(config.idle_timeout)
        .max_lifetime(config.max_lifetime)
        .connect(&config.url)
        .await
}

// src/bulk_operations.rs
use futures::future::try_join_all;

pub async fn bulk_insert_users(
    pool: &PgPool,
    users: Vec<CreateUserRequest>,
) -> Result<Vec<User>, sqlx::Error> {
    let mut tx = pool.begin().await?;
    
    let futures = users.into_iter().map(|user| {
        sqlx::query_as!(
            User,
            r#"
            INSERT INTO users (username, email, password_hash)
            VALUES ($1, $2, $3)
            RETURNING id, username, email, password_hash, created_at, updated_at
            "#,
            user.username,
            user.email,
            hash_password(&user.password),
        )
        .fetch_one(&mut *tx)
    });
    
    let results = try_join_all(futures).await?;
    tx.commit().await?;
    
    Ok(results)
}

// Optimized bulk update
pub async fn bulk_update_post_status(
    pool: &PgPool,
    post_ids: Vec<Uuid>,
    published: bool,
) -> Result<u64, sqlx::Error> {
    let result = sqlx::query!(
        r#"
        UPDATE posts
        SET published = $1, updated_at = NOW()
        WHERE id = ANY($2)
        "#,
        published,
        &post_ids
    )
    .execute(pool)
    .await?;
    
    Ok(result.rows_affected())
}

// src/database_testing.rs
#[cfg(test)]
mod tests {
    use super::*;
    use sqlx::PgPool;
    
    async fn setup_test_db() -> PgPool {
        let database_url = "postgres://postgres:password@localhost/test_db";
        let pool = PgPool::connect(database_url).await.unwrap();
        
        // Run migrations
        sqlx::migrate!("./migrations")
            .run(&pool)
            .await
            .unwrap();
        
        pool
    }
    
    async fn cleanup_test_db(pool: &PgPool) {
        sqlx::query!("TRUNCATE users, posts CASCADE")
            .execute(pool)
            .await
            .unwrap();
    }
    
    #[tokio::test]
    async fn test_user_creation() {
        let pool = setup_test_db().await;
        let user_repo = UserRepository::new(pool.clone());
        
        let req = CreateUserRequest {
            username: "testuser".to_string(),
            email: "test@example.com".to_string(),
            password: "password".to_string(),
        };
        
        let user = user_repo.create(req).await.unwrap();
        assert_eq!(user.username, "testuser");
        assert_eq!(user.email, "test@example.com");
        
        cleanup_test_db(&pool).await;
    }
}

// src/query_builder.rs
use sqlx::{QueryBuilder, Postgres};

pub struct PostFilter {
    pub user_id: Option<Uuid>,
    pub published: Option<bool>,
    pub title_contains: Option<String>,
    pub created_after: Option<DateTime<Utc>>,
}

pub async fn find_posts_with_filter(
    pool: &PgPool,
    filter: PostFilter,
) -> Result<Vec<Post>, sqlx::Error> {
    let mut query = QueryBuilder::<Postgres>::new(
        "SELECT id, user_id, title, content, published, created_at, updated_at FROM posts WHERE 1=1"
    );
    
    if let Some(user_id) = filter.user_id {
        query.push(" AND user_id = ");
        query.push_bind(user_id);
    }
    
    if let Some(published) = filter.published {
        query.push(" AND published = ");
        query.push_bind(published);
    }
    
    if let Some(title) = filter.title_contains {
        query.push(" AND title ILIKE ");
        query.push_bind(format!("%{}%", title));
    }
    
    if let Some(created_after) = filter.created_after {
        query.push(" AND created_at > ");
        query.push_bind(created_after);
    }
    
    query.push(" ORDER BY created_at DESC");
    
    let posts = query
        .build_query_as::<Post>()
        .fetch_all(pool)
        .await?;
    
    Ok(posts)
}
```

## Performance and Best Practices

```rust
// src/performance.rs
use sqlx::{PgPool, postgres::PgRow, Row};
use futures::stream::{StreamExt, TryStreamExt};

// Streaming large result sets
pub async fn export_all_posts(pool: &PgPool) -> Result<(), Box<dyn std::error::Error>> {
    let mut stream = sqlx::query!(
        r#"
        SELECT id, title, content, created_at
        FROM posts
        WHERE published = true
        ORDER BY created_at DESC
        "#
    )
    .fetch(pool);
    
    let mut count = 0;
    while let Some(row) = stream.try_next().await? {
        // Process each row without loading all into memory
        println!("Exporting post: {} - {}", row.id, row.title);
        count += 1;
        
        if count % 1000 == 0 {
            println!("Processed {} posts...", count);
        }
    }
    
    println!("Export complete. Total posts: {}", count);
    Ok(())
}

// Prepared statements for repeated queries
pub struct PreparedQueries {
    find_user_by_id: sqlx::query::Query<'static, Postgres, PgRow>,
    find_posts_by_user: sqlx::query::Query<'static, Postgres, PgRow>,
}

impl PreparedQueries {
    pub fn new() -> Self {
        Self {
            find_user_by_id: sqlx::query!(
                r#"
                SELECT id, username, email, password_hash, created_at, updated_at
                FROM users
                WHERE id = $1
                "#,
                Uuid::nil() // Placeholder
            ),
            find_posts_by_user: sqlx::query!(
                r#"
                SELECT id, user_id, title, content, published, created_at, updated_at
                FROM posts
                WHERE user_id = $1
                ORDER BY created_at DESC
                "#,
                Uuid::nil() // Placeholder
            ),
        }
    }
}

// Connection pooling best practices
pub struct DatabaseManager {
    pool: PgPool,
    health_check_interval: Duration,
}

impl DatabaseManager {
    pub async fn new(database_url: &str) -> Result<Self, sqlx::Error> {
        let pool = PgPoolOptions::new()
            .max_connections(30)
            .min_connections(5)
            .connect_timeout(Duration::from_secs(5))
            .idle_timeout(Duration::from_secs(300))
            .max_lifetime(Duration::from_secs(1800))
            .test_before_acquire(true)
            .connect(database_url)
            .await?;
        
        Ok(Self {
            pool,
            health_check_interval: Duration::from_secs(30),
        })
    }
    
    pub async fn health_check(&self) -> Result<(), sqlx::Error> {
        sqlx::query!("SELECT 1 as check")
            .fetch_one(&self.pool)
            .await?;
        Ok(())
    }
    
    pub fn get_pool(&self) -> &PgPool {
        &self.pool
    }
    
    pub async fn run_health_check_loop(&self) {
        let mut interval = tokio::time::interval(self.health_check_interval);
        
        loop {
            interval.tick().await;
            match self.health_check().await {
                Ok(_) => println!("Database health check: OK"),
                Err(e) => eprintln!("Database health check failed: {}", e),
            }
        }
    }
}

// Index hints and query optimization
pub async fn optimized_user_search(
    pool: &PgPool,
    username_prefix: &str,
) -> Result<Vec<User>, sqlx::Error> {
    // Using index on username for prefix search
    let users = sqlx::query_as!(
        User,
        r#"
        SELECT id, username, email, password_hash, created_at, updated_at
        FROM users
        WHERE username LIKE $1
        ORDER BY username
        LIMIT 10
        "#,
        format!("{}%", username_prefix)
    )
    .fetch_all(pool)
    .await?;
    
    Ok(users)
}

// Batch processing with chunks
pub async fn process_users_in_batches<F>(
    pool: &PgPool,
    batch_size: i64,
    mut processor: F,
) -> Result<(), sqlx::Error>
where
    F: FnMut(Vec<User>) -> Result<(), Box<dyn std::error::Error>>,
{
    let mut last_id = Uuid::nil();
    
    loop {
        let batch = sqlx::query_as!(
            User,
            r#"
            SELECT id, username, email, password_hash, created_at, updated_at
            FROM users
            WHERE id > $1
            ORDER BY id
            LIMIT $2
            "#,
            last_id,
            batch_size
        )
        .fetch_all(pool)
        .await?;
        
        if batch.is_empty() {
            break;
        }
        
        last_id = batch.last().unwrap().id;
        processor(batch)?;
    }
    
    Ok(())
}
```

## Exercises

1. **Migration System**: Create a custom migration system that tracks schema versions and supports rollbacks.

2. **Query Builder**: Build a type-safe query builder that generates SQL at compile time using macros.

3. **Connection Pool Monitor**: Implement a monitoring system that tracks pool statistics, slow queries, and connection health.

4. **Data Sync**: Create a system that syncs data between PostgreSQL and another data store (like Redis) using CDC (Change Data Capture).

5. **Database Testing**: Build a test framework that automatically creates isolated test databases for parallel test execution.

## Key Takeaways

- Diesel provides compile-time safety with a schema-first approach
- SQLx offers async operations with compile-time checked queries
- Use connection pooling for production applications
- Transactions ensure data consistency for related operations
- Prepared statements improve performance for repeated queries
- Stream large result sets to avoid memory issues
- Index your queries appropriately for performance
- Test database operations with isolated test databases
- Use migrations for schema version control
- Consider query builders for dynamic queries

## Next Steps

In Tutorial 14, we'll explore **Web Services**, learning how to build REST APIs with frameworks like Actix-web and Axum, integrating with the database patterns we've learned.